# Litestar Workflows - Architecture Plan

> A workflow automation library for Litestar with support for human approval chains, automated pipelines, and web-based workflow management.

---

## Current Status

**Version**: 0.4.0 (Alpha)
**Phase**: 3 - Web Plugin (Complete)
**Last Updated**: 2025-11-26

### Test Coverage

| Metric | Value |
|--------|-------|
| Total Tests | 461 |
| Coverage | 91% |
| Target | 96% |

### Coverage Gaps

| Module | Coverage | Priority | Notes |
|--------|----------|----------|-------|
| `web/controllers.py` | 82% | Medium | Some error paths need cleanup |
| `core/protocols.py` | 73% | High | Protocol method implementations |
| `db/migrations/env.py` | 0% | Low | Alembic env file, skip |
| `web/exceptions.py` | 76% | Medium | Exception handlers |
| `steps/base.py` | 85% | Low | Near target |
| `contrib/*` | 0% | Low | Stub implementations (expected) |

### Branch Status

All phase branches have been merged to `main`. Local feature branches can be cleaned up:
- `feat/phase1-core-foundation` - Merged
- `feat/phase2-persistence-paused` - Merged
- `feat/phase3-web-plugin` - Merged

### Completed

#### Phase 1: Core Foundation âœ…
- [x] Project scaffolding and tooling
- [x] CI/CD pipelines (ci.yml, docs.yml, cd.yml)
- [x] Documentation infrastructure (Sphinx + Shibuya)
- [x] Core protocols (`Step`, `Workflow`, `ExecutionEngine`)
- [x] Type system (`StepType`, `StepStatus`, `WorkflowStatus`)
- [x] `WorkflowContext` implementation
- [x] `WorkflowDefinition` and `Edge` classes
- [x] Graph builder (`WorkflowGraph`)
- [x] `LocalExecutionEngine` (in-memory)
- [x] `WorkflowRegistry` for definition management
- [x] Built-in steps: `BaseMachineStep`, `BaseHumanStep`
- [x] Step groups: `SequentialGroup`, `ParallelGroup`, `ConditionalGroup`
- [x] Gateway steps: `ExclusiveGateway`, `ParallelGateway`
- [x] Timer steps: `TimerStep`, `DelayStep`, `ScheduledStep`
- [x] Webhook step: `WebhookStep`
- [x] Domain events (workflow lifecycle)
- [x] Exception hierarchy

#### Phase 2: Persistence Layer âœ…
- [x] SQLAlchemy models (WorkflowDefinition, WorkflowInstance, StepExecution, HumanTask)
- [x] Repository pattern (WorkflowDefinitionRepository, WorkflowInstanceRepository, etc.)
- [x] `PersistentExecutionEngine` with database backing
- [x] Alembic migrations support
- [x] Multi-tenancy support (tenant_id filtering)
- [x] 40 database integration tests

#### Phase 3: Web Plugin âœ…
- [x] REST API controllers (definitions, instances, tasks)
- [x] DTOs with validation (StartWorkflowDTO, WorkflowInstanceDTO, etc.)
- [x] MermaidJS graph generation
- [x] OpenAPI schema integration
- [x] Guard integration for auth
- [x] **Merged into core** - REST API auto-enabled with `WorkflowPlugin`
- [x] Graceful degradation without `[db]` extra (501 with helpful message)
- [x] zizmor security scanner in CI
- [x] 50 web API tests

### Next Up

#### Immediate Priorities (Pre-Phase 4)

- [ ] **Boost test coverage to 96%** - Focus on `web/controllers.py` (51%) and `core/protocols.py` (73%)
- [x] **Create `contrib/` directory** - Stub implementations for future task queue integrations
- [x] **Documentation Enhancement** - Comprehensive documentation improvements (see below)

##### Documentation Enhancement Sprint âœ…

Documentation improvements coordinated to enhance developer experience:

- [x] **Persistence Guide** (`docs/guides/persistence.rst`)
  - Database setup with Alembic migrations
  - PersistentExecutionEngine usage
  - Repository API documentation
  - Human task management
  - Multi-tenancy support
  - Database schema reference

- [x] **REST API Guide** (`docs/guides/web-plugin.rst`)
  - Full endpoint reference with examples
  - Authentication and authorization patterns
  - OpenAPI schema customization
  - MermaidJS graph visualization
  - Frontend integration examples
  - Error handling guide

- [x] **Cookbook Examples** (`docs/cookbook/`)
  - End-to-end example applications (expense approval, document review, onboarding)
  - Common workflow patterns
  - Integration recipes (external APIs, error handling, testing)

- [x] **API Reference Enhancement** (`docs/api/`)
  - Auto-generated module documentation for all packages
  - Cross-references between modules
  - Type annotation documentation

- [x] **Contrib Directory** (`src/litestar_workflows/contrib/`)
  - Stub implementations for CeleryExecutionEngine
  - Stub implementations for SAQExecutionEngine
  - Stub implementations for ARQExecutionEngine

#### Phase 4: Advanced Features (v0.5.0)

- [ ] Workflow signals (pause, resume, escalate)
- [ ] Retry policies with exponential backoff
- [ ] Step timeouts and deadlines
- [ ] Workflow versioning and migration
- [ ] Bulk operations (cancel all, retry failed)
- [ ] Audit logging

#### Phase 5: UI Extra (v0.6.0)

- [ ] Tailwind CSS styling
- [ ] Drag-and-drop workflow builder
- [ ] Human task forms (JSON Schema rendering)
- [ ] Instance graph visualization (MermaidJS live)
- [ ] Real-time updates (WebSocket/SSE)

#### Phase 6: Distributed Execution (v0.7.0)

- [ ] `CeleryExecutionEngine` in `contrib/celery/`
- [ ] `SAQExecutionEngine` in `contrib/saq/`
- [ ] `ARQExecutionEngine` in `contrib/arq/`
- [ ] Delayed step execution
- [ ] Dead letter handling

### CI/CD Infrastructure

| Workflow | Purpose | Status |
|----------|---------|--------|
| `ci.yml` | Lint, format, type-check, test (OS matrix) | Active |
| `docs.yml` | Build & deploy docs to GitHub Pages | Active |
| `cd.yml` | git-cliff changelog, PyPI publish, Sigstore | Active |

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Research Analysis](#research-analysis)
3. [Architecture Overview](#architecture-overview)
4. [Core Domain Model](#core-domain-model)
5. [Execution Engine](#execution-engine)
6. [Persistence Layer](#persistence-layer)
7. [Web Plugin](#web-plugin)
8. [Extension Points](#extension-points)
9. [Package Structure](#package-structure)
10. [Implementation Phases](#implementation-phases)
11. [API Reference](#api-reference)

---

## Executive Summary

**litestar-workflows** provides a flexible, async-first workflow automation framework built specifically for the Litestar ecosystem. It draws inspiration from:

- **Joeflow 2.0**: Human/machine task model, lean automation philosophy
- **Prefect 3.0**: DAG-free dynamic execution, event-driven patterns
- **Airflow**: Modular task design, templated fields, provider patterns
- **Celery Canvas**: Composable primitives (chains, groups, chords)

### Key Design Principles

1. **Async-First**: Native `async/await` throughout, leveraging Litestar's async foundation
2. **Lean Automation**: Automate the common path, allow human intervention for exceptions
3. **Composable**: Build complex workflows from simple primitives
4. **Plugin Architecture**: Core library + optional extras (web, celery, etc.)
5. **Type-Safe**: Full typing with Protocol-based interfaces
6. **Litestar-Native**: Deep integration with DI, guards, middleware, and plugins

---

## Research Analysis

### Joeflow 2.0 (Django)

| Aspect | Implementation | Relevance |
|--------|---------------|-----------|
| Task Types | HUMAN (views) + MACHINE (functions) | Adopt for approval workflows |
| State Model | SCHEDULED, SUCCEEDED, FAILED, CANCELED | Extend with PENDING, RUNNING, PAUSED |
| Edges | List of tuples defining transitions | Use for graph definition |
| Visualization | MermaidJS in admin | Adopt for web UI |
| Philosophy | "Handle main cases, users handle exceptions" | Core design principle |

### Prefect 3.0

| Pattern | Description | Application |
|---------|-------------|-------------|
| Monoflow | Linear task chain with tight coupling | Simple sequential workflows |
| Subflow | Nested flows for modularity | Complex multi-stage workflows |
| Orchestrator | Deploy and call remote flows | Distributed execution |
| Event-Driven | Trigger on external events | Webhook/message integration |

### Celery Canvas

| Primitive | Purpose | Adaptation |
|-----------|---------|------------|
| Signature | Deferred task invocation | `StepSignature` for lazy binding |
| Chain | Sequential with result passing | `SequentialGroup` |
| Group | Parallel execution | `ParallelGroup` |
| Chord | Parallel with callback | `ParallelGroup` + callback step |

### Python State Machine Libraries

- **pytransitions**: Async support, hierarchical states, persistence hooks
- **python-statemachine**: Declarative API, guards, validators, async engine

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Application                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      litestar-workflows[web]                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Controllers  â”‚  â”‚    Views     â”‚  â”‚     OpenAPI Schema       â”‚  â”‚
â”‚  â”‚  (REST API)  â”‚  â”‚  (Templates) â”‚  â”‚     (Auto-generated)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      litestar-workflows[db]                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Models     â”‚  â”‚ Repositories â”‚  â”‚      Migrations          â”‚  â”‚
â”‚  â”‚ (SQLAlchemy) â”‚  â”‚   (CRUD)     â”‚  â”‚      (Alembic)           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        litestar-workflows                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Core      â”‚  â”‚   Engine     â”‚  â”‚       Registry           â”‚  â”‚
â”‚  â”‚  (Protocols) â”‚  â”‚  (Executor)  â”‚  â”‚   (Workflow Store)       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     Optional Executors                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Local     â”‚  â”‚    Celery    â”‚  â”‚        SAQ/ARQ           â”‚  â”‚
â”‚  â”‚  (In-proc)   â”‚  â”‚   (Broker)   â”‚  â”‚    (Redis Queue)         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Core Domain Model

### Step Protocol

```python
from typing import Protocol, TypeVar, Any, Generic
from collections.abc import Awaitable

T = TypeVar("T")
ContextT = TypeVar("ContextT", bound="WorkflowContext")

class Step(Protocol[T]):
    """Protocol defining a workflow step."""

    name: str
    description: str

    async def execute(self, context: WorkflowContext) -> T:
        """Execute the step with the given context."""
        ...

    async def can_execute(self, context: WorkflowContext) -> bool:
        """Check if step can execute (guards/validators)."""
        ...

    async def on_success(self, context: WorkflowContext, result: T) -> None:
        """Hook called after successful execution."""
        ...

    async def on_failure(self, context: WorkflowContext, error: Exception) -> None:
        """Hook called after failed execution."""
        ...
```

### Step Types

```python
from enum import StrEnum, auto

class StepType(StrEnum):
    """Classification of step types."""
    MACHINE = auto()   # Automated execution
    HUMAN = auto()     # Requires user interaction
    WEBHOOK = auto()   # Waits for external callback
    TIMER = auto()     # Waits for time condition
    GATEWAY = auto()   # Decision/branching point

class StepStatus(StrEnum):
    """Step execution status."""
    PENDING = auto()     # Not yet scheduled
    SCHEDULED = auto()   # Queued for execution
    RUNNING = auto()     # Currently executing
    WAITING = auto()     # Waiting for input/event
    SUCCEEDED = auto()   # Completed successfully
    FAILED = auto()      # Execution failed
    CANCELED = auto()    # Manually canceled
    SKIPPED = auto()     # Skipped due to condition
```

### Workflow Definition

```python
from dataclasses import dataclass, field
from typing import TypeVar, Generic, ClassVar

WorkflowT = TypeVar("WorkflowT", bound="Workflow")

@dataclass
class Edge:
    """Defines a transition between steps."""
    source: str | type[Step]
    target: str | type[Step]
    condition: str | None = None  # SpEL-like expression or callable name

@dataclass
class WorkflowDefinition:
    """Declarative workflow structure."""
    name: str
    version: str
    description: str
    steps: dict[str, Step]
    edges: list[Edge]
    initial_step: str
    terminal_steps: set[str] = field(default_factory=set)

    def get_graph(self) -> "WorkflowGraph":
        """Build graph representation."""
        ...

    def to_mermaid(self) -> str:
        """Generate MermaidJS diagram."""
        ...

class Workflow(Generic[WorkflowT]):
    """Base class for workflow implementations."""

    # Class-level definition
    __workflow_name__: ClassVar[str]
    __workflow_version__: ClassVar[str] = "1.0.0"
    __edges__: ClassVar[list[tuple[str, str]]]

    # Instance state
    context: WorkflowContext
    current_step: str | None
    status: WorkflowStatus

    @classmethod
    def get_definition(cls) -> WorkflowDefinition:
        """Extract workflow definition from class."""
        ...

    async def start(self, initial_data: dict[str, Any] | None = None) -> "WorkflowInstance":
        """Start a new workflow instance."""
        ...

    async def resume(self, instance_id: str) -> "WorkflowInstance":
        """Resume a paused workflow instance."""
        ...
```

### Workflow Context

```python
from typing import Any, TypeVar
from datetime import datetime
from uuid import UUID

@dataclass
class WorkflowContext:
    """Execution context passed between steps."""

    # Identity
    workflow_id: UUID
    instance_id: UUID

    # State
    data: dict[str, Any]  # Mutable workflow data
    metadata: dict[str, Any]  # Immutable metadata

    # Execution info
    current_step: str
    step_history: list["StepExecution"]
    started_at: datetime

    # User context (for human tasks)
    user_id: str | None = None
    tenant_id: str | None = None

    def get(self, key: str, default: Any = None) -> Any:
        """Get value from data with default."""
        return self.data.get(key, default)

    def set(self, key: str, value: Any) -> None:
        """Set value in data."""
        self.data[key] = value

    def with_step(self, step_name: str) -> "WorkflowContext":
        """Create new context for step execution."""
        ...
```

### Composable Step Groups

```python
from abc import ABC, abstractmethod

class StepGroup(ABC):
    """Base for composable step patterns."""

    @abstractmethod
    async def execute(self, context: WorkflowContext, engine: "ExecutionEngine") -> Any:
        """Execute the step group."""
        ...

class SequentialGroup(StepGroup):
    """Execute steps in sequence, passing results."""

    def __init__(self, *steps: Step | StepGroup):
        self.steps = steps

    async def execute(self, context: WorkflowContext, engine: "ExecutionEngine") -> Any:
        result = None
        for step in self.steps:
            result = await engine.execute_step(step, context, previous_result=result)
        return result

class ParallelGroup(StepGroup):
    """Execute steps in parallel."""

    def __init__(self, *steps: Step | StepGroup, callback: Step | None = None):
        self.steps = steps
        self.callback = callback  # Chord pattern

    async def execute(self, context: WorkflowContext, engine: "ExecutionEngine") -> list[Any]:
        results = await asyncio.gather(
            *[engine.execute_step(step, context) for step in self.steps]
        )
        if self.callback:
            return await engine.execute_step(self.callback, context, previous_result=results)
        return results

class ConditionalGroup(StepGroup):
    """Execute one of multiple branches based on condition."""

    def __init__(self, condition: Callable[[WorkflowContext], str], branches: dict[str, Step | StepGroup]):
        self.condition = condition
        self.branches = branches

    async def execute(self, context: WorkflowContext, engine: "ExecutionEngine") -> Any:
        branch_key = self.condition(context)
        if branch_key in self.branches:
            return await engine.execute_step(self.branches[branch_key], context)
        return None
```

---

## Execution Engine

### Engine Protocol

```python
from typing import Protocol

class ExecutionEngine(Protocol):
    """Protocol for workflow execution engines."""

    async def start_workflow(
        self,
        workflow: type[Workflow],
        initial_data: dict[str, Any] | None = None
    ) -> WorkflowInstance:
        """Start a new workflow instance."""
        ...

    async def execute_step(
        self,
        step: Step | StepGroup,
        context: WorkflowContext,
        previous_result: Any = None
    ) -> Any:
        """Execute a single step or group."""
        ...

    async def schedule_step(
        self,
        instance_id: UUID,
        step_name: str,
        delay: timedelta | None = None
    ) -> None:
        """Schedule a step for later execution."""
        ...

    async def complete_human_task(
        self,
        instance_id: UUID,
        step_name: str,
        user_id: str,
        data: dict[str, Any]
    ) -> None:
        """Complete a human task with user input."""
        ...

    async def cancel_workflow(self, instance_id: UUID, reason: str) -> None:
        """Cancel a running workflow."""
        ...
```

### Local Engine Implementation

```python
class LocalExecutionEngine:
    """In-process async execution engine."""

    def __init__(
        self,
        registry: "WorkflowRegistry",
        persistence: "WorkflowPersistence | None" = None,
        event_bus: "EventBus | None" = None
    ):
        self.registry = registry
        self.persistence = persistence
        self.event_bus = event_bus
        self._running: dict[UUID, asyncio.Task] = {}

    async def start_workflow(
        self,
        workflow: type[Workflow],
        initial_data: dict[str, Any] | None = None
    ) -> WorkflowInstance:
        # Create instance
        instance = WorkflowInstance(
            id=uuid4(),
            workflow_name=workflow.__workflow_name__,
            workflow_version=workflow.__workflow_version__,
            status=WorkflowStatus.RUNNING,
            context=WorkflowContext(
                workflow_id=workflow.get_definition().name,
                instance_id=uuid4(),
                data=initial_data or {},
                metadata={},
                current_step=workflow.get_definition().initial_step,
                step_history=[],
                started_at=datetime.utcnow()
            )
        )

        # Persist
        if self.persistence:
            await self.persistence.save_instance(instance)

        # Emit event
        if self.event_bus:
            await self.event_bus.emit(WorkflowStarted(instance_id=instance.id))

        # Start execution
        self._running[instance.id] = asyncio.create_task(
            self._run_workflow(instance)
        )

        return instance

    async def _run_workflow(self, instance: WorkflowInstance) -> None:
        """Main workflow execution loop."""
        definition = self.registry.get_definition(instance.workflow_name)
        graph = definition.get_graph()

        while instance.status == WorkflowStatus.RUNNING:
            current = instance.context.current_step
            step = definition.steps[current]

            # Check if human task - pause and wait
            if step.step_type == StepType.HUMAN:
                instance.status = WorkflowStatus.WAITING
                if self.persistence:
                    await self.persistence.save_instance(instance)
                return  # Will be resumed by complete_human_task

            # Execute machine task
            try:
                if await step.can_execute(instance.context):
                    result = await step.execute(instance.context)
                    await step.on_success(instance.context, result)

                    # Record execution
                    instance.context.step_history.append(
                        StepExecution(
                            step_name=current,
                            status=StepStatus.SUCCEEDED,
                            result=result,
                            completed_at=datetime.utcnow()
                        )
                    )
                else:
                    instance.context.step_history.append(
                        StepExecution(
                            step_name=current,
                            status=StepStatus.SKIPPED,
                            completed_at=datetime.utcnow()
                        )
                    )
            except Exception as e:
                await step.on_failure(instance.context, e)
                instance.status = WorkflowStatus.FAILED
                instance.error = str(e)
                break

            # Find next step(s)
            next_steps = graph.get_next_steps(current, instance.context)

            if not next_steps:
                # No more steps - workflow complete
                instance.status = WorkflowStatus.COMPLETED
                break
            elif len(next_steps) == 1:
                instance.context.current_step = next_steps[0]
            else:
                # Parallel execution needed
                # Implementation depends on whether parallel or conditional
                ...

            # Persist progress
            if self.persistence:
                await self.persistence.save_instance(instance)

        # Workflow finished
        if self.persistence:
            await self.persistence.save_instance(instance)
        if self.event_bus:
            await self.event_bus.emit(
                WorkflowCompleted(instance_id=instance.id, status=instance.status)
            )
```

### Celery Engine (Optional Extra)

```python
# litestar_workflows/contrib/celery.py

class CeleryExecutionEngine:
    """Celery-based distributed execution engine."""

    def __init__(self, celery_app: Celery, persistence: WorkflowPersistence):
        self.celery = celery_app
        self.persistence = persistence
        self._register_tasks()

    def _register_tasks(self) -> None:
        """Register Celery tasks for step execution."""

        @self.celery.task(bind=True)
        def execute_step_task(self, instance_id: str, step_name: str):
            # Load instance and execute step
            ...

    async def schedule_step(
        self,
        instance_id: UUID,
        step_name: str,
        delay: timedelta | None = None
    ) -> None:
        if delay:
            execute_step_task.apply_async(
                args=[str(instance_id), step_name],
                countdown=delay.total_seconds()
            )
        else:
            execute_step_task.delay(str(instance_id), step_name)
```

---

## Persistence Layer

### Repository Pattern

```python
from typing import Protocol, Generic, TypeVar
from uuid import UUID

ModelT = TypeVar("ModelT")

class Repository(Protocol[ModelT]):
    """Generic repository protocol."""

    async def get(self, id: UUID) -> ModelT | None: ...
    async def get_many(self, ids: list[UUID]) -> list[ModelT]: ...
    async def save(self, entity: ModelT) -> ModelT: ...
    async def delete(self, id: UUID) -> bool: ...

class WorkflowInstanceRepository(Repository["WorkflowInstance"]):
    """Repository for workflow instances."""

    async def find_by_workflow(
        self,
        workflow_name: str,
        status: WorkflowStatus | None = None,
        limit: int = 100,
        offset: int = 0
    ) -> list[WorkflowInstance]: ...

    async def find_by_user(
        self,
        user_id: str,
        status: WorkflowStatus | None = None
    ) -> list[WorkflowInstance]: ...

    async def find_pending_human_tasks(
        self,
        user_id: str | None = None,
        workflow_name: str | None = None
    ) -> list[tuple[WorkflowInstance, str]]: ...
```

### SQLAlchemy Models

```python
# litestar_workflows/db/models.py

from datetime import datetime
from uuid import UUID
from sqlalchemy import String, JSON, DateTime, ForeignKey, Enum
from sqlalchemy.orm import Mapped, mapped_column, relationship
from litestar.contrib.sqlalchemy.base import UUIDAuditBase

class WorkflowDefinitionModel(UUIDAuditBase):
    """Persisted workflow definition (for versioning)."""

    __tablename__ = "workflow_definitions"

    name: Mapped[str] = mapped_column(String(255), index=True)
    version: Mapped[str] = mapped_column(String(50))
    description: Mapped[str | None] = mapped_column(String(1000))
    definition_json: Mapped[dict] = mapped_column(JSON)  # Serialized WorkflowDefinition
    is_active: Mapped[bool] = mapped_column(default=True)

    instances: Mapped[list["WorkflowInstanceModel"]] = relationship(back_populates="definition")

class WorkflowInstanceModel(UUIDAuditBase):
    """Persisted workflow instance."""

    __tablename__ = "workflow_instances"

    definition_id: Mapped[UUID] = mapped_column(ForeignKey("workflow_definitions.id"))
    status: Mapped[str] = mapped_column(String(50), index=True)
    current_step: Mapped[str | None] = mapped_column(String(255))
    context_data: Mapped[dict] = mapped_column(JSON)
    metadata: Mapped[dict] = mapped_column(JSON, default=dict)
    error: Mapped[str | None] = mapped_column(String(2000))
    started_at: Mapped[datetime] = mapped_column(DateTime)
    completed_at: Mapped[datetime | None] = mapped_column(DateTime)

    # Multi-tenancy support
    tenant_id: Mapped[str | None] = mapped_column(String(255), index=True)
    created_by: Mapped[str | None] = mapped_column(String(255))

    definition: Mapped[WorkflowDefinitionModel] = relationship(back_populates="instances")
    step_executions: Mapped[list["StepExecutionModel"]] = relationship(back_populates="instance")

class StepExecutionModel(UUIDAuditBase):
    """Persisted step execution record."""

    __tablename__ = "workflow_step_executions"

    instance_id: Mapped[UUID] = mapped_column(ForeignKey("workflow_instances.id"))
    step_name: Mapped[str] = mapped_column(String(255))
    step_type: Mapped[str] = mapped_column(String(50))
    status: Mapped[str] = mapped_column(String(50))
    input_data: Mapped[dict | None] = mapped_column(JSON)
    output_data: Mapped[dict | None] = mapped_column(JSON)
    error: Mapped[str | None] = mapped_column(String(2000))
    started_at: Mapped[datetime] = mapped_column(DateTime)
    completed_at: Mapped[datetime | None] = mapped_column(DateTime)

    # For human tasks
    assigned_to: Mapped[str | None] = mapped_column(String(255))
    completed_by: Mapped[str | None] = mapped_column(String(255))

    instance: Mapped[WorkflowInstanceModel] = relationship(back_populates="step_executions")

class HumanTaskModel(UUIDAuditBase):
    """Pending human tasks for quick querying."""

    __tablename__ = "workflow_human_tasks"

    instance_id: Mapped[UUID] = mapped_column(ForeignKey("workflow_instances.id"))
    step_execution_id: Mapped[UUID] = mapped_column(ForeignKey("workflow_step_executions.id"))
    step_name: Mapped[str] = mapped_column(String(255))
    title: Mapped[str] = mapped_column(String(500))
    description: Mapped[str | None] = mapped_column(String(2000))
    form_schema: Mapped[dict | None] = mapped_column(JSON)  # JSON Schema for form

    # Assignment
    assignee_id: Mapped[str | None] = mapped_column(String(255), index=True)
    assignee_group: Mapped[str | None] = mapped_column(String(255), index=True)

    # Deadlines
    due_at: Mapped[datetime | None] = mapped_column(DateTime)
    reminder_at: Mapped[datetime | None] = mapped_column(DateTime)

    # Status
    status: Mapped[str] = mapped_column(String(50), default="PENDING")
    completed_at: Mapped[datetime | None] = mapped_column(DateTime)
```

### SQLAlchemy Repository Implementation

```python
# litestar_workflows/db/repositories.py

from litestar.contrib.sqlalchemy.repository import SQLAlchemyAsyncRepository

class WorkflowInstanceSQLRepository(SQLAlchemyAsyncRepository[WorkflowInstanceModel]):
    """SQLAlchemy implementation of workflow instance repository."""

    model_type = WorkflowInstanceModel

    async def find_pending_human_tasks(
        self,
        user_id: str | None = None,
        workflow_name: str | None = None
    ) -> list[HumanTaskModel]:
        stmt = select(HumanTaskModel).where(HumanTaskModel.status == "PENDING")

        if user_id:
            stmt = stmt.where(
                or_(
                    HumanTaskModel.assignee_id == user_id,
                    HumanTaskModel.assignee_id.is_(None)
                )
            )

        result = await self.session.execute(stmt)
        return list(result.scalars().all())
```

---

## Web Plugin

### Plugin Architecture

```python
# litestar_workflows/web/plugin.py

from litestar.plugins import InitPluginProtocol
from litestar.config.app import AppConfig
from litestar.di import Provide
from litestar.router import Router

class WorkflowWebPlugin(InitPluginProtocol):
    """Litestar plugin for workflow web routes."""

    def __init__(
        self,
        *,
        path_prefix: str = "/workflows",
        enable_admin: bool = True,
        enable_api: bool = True,
        enable_ui: bool = False,
        auth_guard: type | None = None,
        admin_guard: type | None = None,
        include_in_schema: bool = True,
        tags: list[str] | None = None
    ):
        self.path_prefix = path_prefix
        self.enable_admin = enable_admin
        self.enable_api = enable_api
        self.enable_ui = enable_ui
        self.auth_guard = auth_guard
        self.admin_guard = admin_guard
        self.include_in_schema = include_in_schema
        self.tags = tags or ["Workflows"]

    def on_app_init(self, app_config: AppConfig) -> AppConfig:
        """Register workflow routes on app initialization."""

        routers = []

        if self.enable_api:
            routers.append(self._create_api_router())

        if self.enable_admin:
            routers.append(self._create_admin_router())

        if self.enable_ui:
            routers.append(self._create_ui_router())

        # Create main workflow router
        workflow_router = Router(
            path=self.path_prefix,
            route_handlers=routers,
            tags=self.tags
        )

        # Add to app routes
        app_config.route_handlers.append(workflow_router)

        # Register dependencies
        app_config.dependencies.update({
            "workflow_engine": Provide(self._provide_engine),
            "workflow_registry": Provide(self._provide_registry),
        })

        return app_config

    def _create_api_router(self) -> Router:
        """Create REST API router."""
        from .controllers import (
            WorkflowDefinitionController,
            WorkflowInstanceController,
            HumanTaskController,
        )

        guards = [self.auth_guard] if self.auth_guard else []

        return Router(
            path="/api",
            route_handlers=[
                WorkflowDefinitionController,
                WorkflowInstanceController,
                HumanTaskController,
            ],
            guards=guards,
            include_in_schema=self.include_in_schema
        )

    def _create_admin_router(self) -> Router:
        """Create admin API router."""
        from .controllers import WorkflowAdminController

        guards = [self.admin_guard] if self.admin_guard else []

        return Router(
            path="/admin",
            route_handlers=[WorkflowAdminController],
            guards=guards
        )

    def _create_ui_router(self) -> Router:
        """Create UI routes with templates."""
        from .views import WorkflowUIController

        return Router(
            path="/ui",
            route_handlers=[WorkflowUIController],
            guards=[self.auth_guard] if self.auth_guard else []
        )
```

### REST API Controllers

```python
# litestar_workflows/web/controllers.py

from litestar import Controller, get, post, put, delete
from litestar.dto import DTOConfig
from litestar.params import Parameter
from uuid import UUID

class WorkflowDefinitionController(Controller):
    """API for workflow definitions."""

    path = "/definitions"
    tags = ["Workflow Definitions"]

    @get("/")
    async def list_definitions(
        self,
        workflow_registry: WorkflowRegistry,
        active_only: bool = True
    ) -> list[WorkflowDefinitionDTO]:
        """List all registered workflow definitions."""
        definitions = workflow_registry.list_definitions(active_only=active_only)
        return [WorkflowDefinitionDTO.from_definition(d) for d in definitions]

    @get("/{name:str}")
    async def get_definition(
        self,
        name: str,
        workflow_registry: WorkflowRegistry,
        version: str | None = None
    ) -> WorkflowDefinitionDTO:
        """Get a specific workflow definition."""
        definition = workflow_registry.get_definition(name, version=version)
        return WorkflowDefinitionDTO.from_definition(definition)

    @get("/{name:str}/graph")
    async def get_graph(
        self,
        name: str,
        workflow_registry: WorkflowRegistry,
        format: str = "mermaid"
    ) -> dict[str, str]:
        """Get workflow graph visualization."""
        definition = workflow_registry.get_definition(name)
        if format == "mermaid":
            return {"graph": definition.to_mermaid()}
        elif format == "dot":
            return {"graph": definition.to_graphviz()}
        raise ValueError(f"Unknown format: {format}")


class WorkflowInstanceController(Controller):
    """API for workflow instances."""

    path = "/instances"
    tags = ["Workflow Instances"]

    @post("/")
    async def start_workflow(
        self,
        data: StartWorkflowDTO,
        workflow_engine: ExecutionEngine,
        workflow_registry: WorkflowRegistry
    ) -> WorkflowInstanceDTO:
        """Start a new workflow instance."""
        workflow_class = workflow_registry.get_workflow_class(data.workflow_name)
        instance = await workflow_engine.start_workflow(
            workflow_class,
            initial_data=data.initial_data
        )
        return WorkflowInstanceDTO.from_instance(instance)

    @get("/")
    async def list_instances(
        self,
        workflow_repo: WorkflowInstanceRepository,
        workflow_name: str | None = None,
        status: WorkflowStatus | None = None,
        limit: int = Parameter(default=50, le=100),
        offset: int = 0
    ) -> list[WorkflowInstanceDTO]:
        """List workflow instances with filtering."""
        instances = await workflow_repo.find_by_workflow(
            workflow_name=workflow_name,
            status=status,
            limit=limit,
            offset=offset
        )
        return [WorkflowInstanceDTO.from_instance(i) for i in instances]

    @get("/{instance_id:uuid}")
    async def get_instance(
        self,
        instance_id: UUID,
        workflow_repo: WorkflowInstanceRepository
    ) -> WorkflowInstanceDetailDTO:
        """Get detailed workflow instance information."""
        instance = await workflow_repo.get(instance_id)
        if not instance:
            raise NotFoundException(f"Instance {instance_id} not found")
        return WorkflowInstanceDetailDTO.from_instance(instance)

    @get("/{instance_id:uuid}/graph")
    async def get_instance_graph(
        self,
        instance_id: UUID,
        workflow_repo: WorkflowInstanceRepository,
        workflow_registry: WorkflowRegistry
    ) -> dict[str, str]:
        """Get instance graph with execution state."""
        instance = await workflow_repo.get(instance_id)
        definition = workflow_registry.get_definition(instance.workflow_name)

        # Generate graph with instance state highlighting
        mermaid = definition.to_mermaid_with_state(
            current_step=instance.current_step,
            completed_steps=[e.step_name for e in instance.step_history if e.status == StepStatus.SUCCEEDED],
            failed_steps=[e.step_name for e in instance.step_history if e.status == StepStatus.FAILED]
        )
        return {"graph": mermaid}

    @post("/{instance_id:uuid}/cancel")
    async def cancel_instance(
        self,
        instance_id: UUID,
        data: CancelWorkflowDTO,
        workflow_engine: ExecutionEngine
    ) -> WorkflowInstanceDTO:
        """Cancel a running workflow instance."""
        await workflow_engine.cancel_workflow(instance_id, reason=data.reason)
        ...

    @post("/{instance_id:uuid}/retry")
    async def retry_instance(
        self,
        instance_id: UUID,
        workflow_engine: ExecutionEngine,
        from_step: str | None = None
    ) -> WorkflowInstanceDTO:
        """Retry a failed workflow from a specific step."""
        ...


class HumanTaskController(Controller):
    """API for human tasks."""

    path = "/tasks"
    tags = ["Human Tasks"]

    @get("/")
    async def list_my_tasks(
        self,
        request: Request,
        workflow_repo: WorkflowInstanceRepository,
        status: str = "PENDING"
    ) -> list[HumanTaskDTO]:
        """List human tasks assigned to current user."""
        user_id = request.user.id  # Assumes auth middleware
        tasks = await workflow_repo.find_pending_human_tasks(user_id=user_id)
        return [HumanTaskDTO.from_model(t) for t in tasks]

    @get("/{task_id:uuid}")
    async def get_task(
        self,
        task_id: UUID,
        task_repo: HumanTaskRepository
    ) -> HumanTaskDetailDTO:
        """Get human task details including form schema."""
        task = await task_repo.get(task_id)
        if not task:
            raise NotFoundException(f"Task {task_id} not found")
        return HumanTaskDetailDTO.from_model(task)

    @post("/{task_id:uuid}/complete")
    async def complete_task(
        self,
        task_id: UUID,
        data: CompleteTaskDTO,
        request: Request,
        workflow_engine: ExecutionEngine,
        task_repo: HumanTaskRepository
    ) -> WorkflowInstanceDTO:
        """Complete a human task with form data."""
        task = await task_repo.get(task_id)
        user_id = request.user.id

        await workflow_engine.complete_human_task(
            instance_id=task.instance_id,
            step_name=task.step_name,
            user_id=user_id,
            data=data.form_data
        )
        ...

    @post("/{task_id:uuid}/reassign")
    async def reassign_task(
        self,
        task_id: UUID,
        data: ReassignTaskDTO,
        task_repo: HumanTaskRepository
    ) -> HumanTaskDTO:
        """Reassign task to another user."""
        ...
```

### DTOs

```python
# litestar_workflows/web/dto.py

from dataclasses import dataclass
from datetime import datetime
from uuid import UUID
from litestar.dto import DataclassDTO, DTOConfig

@dataclass
class StartWorkflowDTO:
    """DTO for starting a workflow."""
    workflow_name: str
    initial_data: dict[str, Any] | None = None

@dataclass
class WorkflowDefinitionDTO:
    """DTO for workflow definition."""
    name: str
    version: str
    description: str
    steps: list[str]
    initial_step: str
    terminal_steps: list[str]

@dataclass
class WorkflowInstanceDTO:
    """DTO for workflow instance."""
    id: UUID
    workflow_name: str
    workflow_version: str
    status: str
    current_step: str | None
    started_at: datetime
    completed_at: datetime | None

@dataclass
class WorkflowInstanceDetailDTO(WorkflowInstanceDTO):
    """Detailed workflow instance DTO."""
    context_data: dict[str, Any]
    step_history: list["StepExecutionDTO"]
    error: str | None

@dataclass
class HumanTaskDTO:
    """DTO for human task."""
    id: UUID
    instance_id: UUID
    step_name: str
    title: str
    description: str | None
    assignee_id: str | None
    due_at: datetime | None
    status: str

@dataclass
class HumanTaskDetailDTO(HumanTaskDTO):
    """Detailed human task DTO with form schema."""
    form_schema: dict[str, Any] | None
    workflow_context: dict[str, Any]

@dataclass
class CompleteTaskDTO:
    """DTO for completing a task."""
    form_data: dict[str, Any]
    comment: str | None = None

@dataclass
class CancelWorkflowDTO:
    """DTO for canceling a workflow."""
    reason: str
```

### OpenAPI Schema Enhancement

```python
# litestar_workflows/web/openapi.py

from litestar.openapi.spec import Tag

WORKFLOW_TAGS = [
    Tag(
        name="Workflow Definitions",
        description="Manage workflow definitions and their schemas"
    ),
    Tag(
        name="Workflow Instances",
        description="Start, monitor, and control workflow executions"
    ),
    Tag(
        name="Human Tasks",
        description="Manage human approval tasks and form submissions"
    ),
]
```

---

## Extension Points

### Custom Step Types

```python
# User-defined step
from litestar_workflows import Step, StepType, WorkflowContext

class SendEmailStep(Step):
    """Custom step for sending emails."""

    name = "send_email"
    description = "Send an email notification"
    step_type = StepType.MACHINE

    def __init__(self, template: str, recipients_key: str = "recipients"):
        self.template = template
        self.recipients_key = recipients_key

    async def execute(self, context: WorkflowContext) -> dict[str, Any]:
        recipients = context.get(self.recipients_key, [])
        # Send email logic...
        return {"sent_to": recipients, "template": self.template}

    async def can_execute(self, context: WorkflowContext) -> bool:
        return bool(context.get(self.recipients_key))
```

### Custom Execution Engines

```python
# SAQ (Simple Async Queue) engine
class SAQExecutionEngine(ExecutionEngine):
    """SAQ-based execution engine for Redis queues."""

    def __init__(self, queue: saq.Queue, persistence: WorkflowPersistence):
        self.queue = queue
        self.persistence = persistence

    async def schedule_step(
        self,
        instance_id: UUID,
        step_name: str,
        delay: timedelta | None = None
    ) -> None:
        await self.queue.enqueue(
            "execute_workflow_step",
            instance_id=str(instance_id),
            step_name=step_name,
            scheduled=datetime.utcnow() + delay if delay else None
        )
```

### Event Hooks

```python
from litestar_workflows.events import WorkflowEvent, on_event

@on_event(WorkflowStarted)
async def notify_on_start(event: WorkflowStarted) -> None:
    """Send notification when workflow starts."""
    ...

@on_event(HumanTaskCreated)
async def assign_task(event: HumanTaskCreated) -> None:
    """Auto-assign task based on rules."""
    ...

@on_event(WorkflowCompleted)
async def cleanup_on_complete(event: WorkflowCompleted) -> None:
    """Cleanup resources after workflow completes."""
    ...
```

### Workflow Decorators (Prefect-style)

```python
from litestar_workflows import workflow, step, human_task

@workflow(name="document_approval", version="1.0.0")
class DocumentApprovalWorkflow:
    """Workflow for document approval process."""

    @step(initial=True)
    async def submit_document(self, context: WorkflowContext) -> str:
        """Initial submission step."""
        return "review"

    @human_task(
        title="Review Document",
        form_schema={"type": "object", "properties": {"approved": {"type": "boolean"}}}
    )
    async def review(self, context: WorkflowContext) -> str:
        """Manager reviews document."""
        if context.get("approved"):
            return "publish"
        return "revise"

    @step
    async def publish(self, context: WorkflowContext) -> None:
        """Publish the approved document."""
        ...

    @step(terminal=True)
    async def revise(self, context: WorkflowContext) -> None:
        """Send back for revision."""
        ...
```

---

## Package Structure

> **Note**: âœ… = Implemented, ðŸ”œ = Planned

```
src/litestar_workflows/
â”œâ”€â”€ __init__.py              # Public API exports âœ…
â”œâ”€â”€ __metadata__.py          # Version info âœ…
â”œâ”€â”€ py.typed                 # PEP 561 marker âœ…
â”œâ”€â”€ plugin.py                # WorkflowPlugin (Litestar integration) âœ…
â”œâ”€â”€ exceptions.py            # Exception hierarchy âœ…
â”‚
â”œâ”€â”€ core/                    # Core domain (no dependencies) âœ…
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ protocols.py         # Step, Workflow protocols
â”‚   â”œâ”€â”€ types.py             # Type definitions, enums
â”‚   â”œâ”€â”€ context.py           # WorkflowContext
â”‚   â”œâ”€â”€ definition.py        # WorkflowDefinition, Edge
â”‚   â”œâ”€â”€ models.py            # WorkflowInstanceData (in-memory)
â”‚   â””â”€â”€ events.py            # Domain events
â”‚
â”œâ”€â”€ engine/                  # Execution engines âœ…
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py              # ExecutionEngine protocol
â”‚   â”œâ”€â”€ local.py             # LocalExecutionEngine
â”‚   â”œâ”€â”€ graph.py             # WorkflowGraph
â”‚   â”œâ”€â”€ instance.py          # WorkflowInstance
â”‚   â””â”€â”€ registry.py          # WorkflowRegistry
â”‚
â”œâ”€â”€ steps/                   # Built-in step implementations âœ…
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py              # BaseStep, BaseMachineStep, BaseHumanStep
â”‚   â”œâ”€â”€ groups.py            # SequentialGroup, ParallelGroup
â”‚   â”œâ”€â”€ gateway.py           # Decision gateways
â”‚   â”œâ”€â”€ timer.py             # Timer/delay steps
â”‚   â””â”€â”€ webhook.py           # WebhookStep
â”‚
â”œâ”€â”€ decorators/              # Decorator-based definition ðŸ”œ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ workflow.py          # @workflow, @step, @human_task
â”‚
â”œâ”€â”€ db/                      # Database extra [db] âœ…
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py            # SQLAlchemy models
â”‚   â”œâ”€â”€ engine.py            # PersistentExecutionEngine
â”‚   â”œâ”€â”€ repositories.py      # Repository implementations
â”‚   â””â”€â”€ migrations/          # Alembic migrations
â”‚       â””â”€â”€ versions/
â”‚
â”œâ”€â”€ web/                     # Web routes (merged into core) âœ…
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py            # WebConfig
â”‚   â”œâ”€â”€ controllers.py       # REST API controllers
â”‚   â”œâ”€â”€ dto.py               # Data transfer objects
â”‚   â”œâ”€â”€ exceptions.py        # HTTP exception handlers
â”‚   â”œâ”€â”€ graph.py             # MermaidJS generation
â”‚   â””â”€â”€ templates/           # Jinja templates (Phase 5 - UI) ðŸ”œ
â”‚       â”œâ”€â”€ base.html
â”‚       â”œâ”€â”€ workflow_list.html
â”‚       â”œâ”€â”€ workflow_detail.html
â”‚       â””â”€â”€ task_form.html
â”‚
â””â”€â”€ contrib/                 # Optional integrations ðŸ”œ
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ celery/              # Celery engine [celery] ðŸ”œ
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ engine.py
    â”œâ”€â”€ saq/                 # SAQ engine [saq] ðŸ”œ
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ engine.py
    â””â”€â”€ arq/                 # ARQ engine [arq] ðŸ”œ
        â”œâ”€â”€ __init__.py
        â””â”€â”€ engine.py
```

### pyproject.toml Extras

```toml
[project.optional-dependencies]
db = [
    "litestar[sqlalchemy]",
    "alembic>=1.13.0",
]
web = [
    "litestar-workflows[db]",  # Web requires DB
]
ui = [
    "litestar-workflows[web]",
    "litestar[jinja]",
]
celery = [
    "celery>=5.3.0",
]
saq = [
    "saq>=0.12.0",
]
arq = [
    "arq>=0.25.0",
]
all = [
    "litestar-workflows[db,web,ui,celery,saq]",
]
```

---

## Implementation Phases

### Phase 1: Core Foundation (v0.2.0) âœ…

**Goal**: Establish core domain model and local execution

**Deliverables**:
- [x] Core protocols (`Step`, `Workflow`, `ExecutionEngine`)
- [x] Type system (`StepType`, `StepStatus`, `WorkflowStatus`)
- [x] `WorkflowContext` implementation
- [x] `WorkflowDefinition` and `Edge` classes
- [x] Graph builder and validation
- [x] `LocalExecutionEngine` (in-memory, no persistence)
- [x] `WorkflowRegistry` for definition management
- [x] Built-in steps: `BaseMachineStep`, `BaseHumanStep`
- [x] Step groups: `SequentialGroup`, `ParallelGroup`
- [x] Exception hierarchy
- [x] Unit tests (439 tests, 89% coverage)
- [x] Basic documentation

### Phase 2: Persistence Layer (v0.3.0) âœ…

**Goal**: Add database persistence with SQLAlchemy

**Deliverables**:
- [x] SQLAlchemy models (`WorkflowDefinition`, `WorkflowInstance`, `StepExecution`, `HumanTask`)
- [x] Repository implementations
- [x] Alembic migration support
- [x] `PersistentExecutionEngine` (wraps local engine with DB)
- [x] Event bus for workflow events
- [x] Query capabilities (find by status, user, etc.)
- [x] Integration tests with test database
- [x] Migration documentation

### Phase 3: Web Plugin (v0.4.0) âœ…

**Goal**: REST API and plugin auto-registration

**Deliverables**:
- [x] REST controllers for definitions, instances, tasks (merged into core)
- [x] DTO layer with validation
- [x] OpenAPI schema generation
- [x] Guard integration for auth
- [x] MermaidJS graph endpoints
- [x] API documentation
- [x] Integration tests for all endpoints
- [x] Graceful degradation without `[db]` (helpful 501 errors)
- [x] zizmor security scanner in CI

**Architecture Decision**: REST API merged into core `WorkflowPlugin`:
- Auto-enabled by default (`enable_api=True`)
- Core endpoints work without `[db]`: GET /definitions, POST /instances
- DB-dependent endpoints require `[db]`: GET /instances, GET /tasks, etc.

### Pre-Phase 4: Stabilization

**Goal**: Reach 96% test coverage and prepare codebase for advanced features

**Deliverables**:
- [ ] Increase `web/controllers.py` coverage from 51% to 90%+
- [ ] Increase `core/protocols.py` coverage from 73% to 90%+
- [ ] Add migration tests for `db/migrations/env.py`
- [ ] Create `contrib/` directory structure with `__init__.py` stubs
- [ ] Add persistence layer usage examples to documentation
- [ ] Add REST API usage examples to documentation
- [ ] Clean up stale local feature branches

### Phase 4: Advanced Features (v0.5.0)

**Goal**: Production-ready workflow features

**Deliverables**:
- [ ] Workflow signals (pause, resume, escalate)
- [ ] Retry policies with backoff
- [ ] Step timeouts and deadlines
- [ ] Workflow versioning and migration
- [ ] Bulk operations (cancel all, retry failed)
- [ ] Audit logging

### Phase 5: UI Extra (v0.6.0)

**Goal**: Modern web UI for workflow management (`[ui]` extra)

**Deliverables**:
- [ ] Tailwind CSS styling
- [ ] Drag-and-drop workflow builder
- [ ] Composable UI components
- [ ] Workflow list/detail views
- [ ] Human task forms (JSON Schema rendering)
- [ ] Instance graph visualization (MermaidJS live)
- [ ] Admin dashboard with metrics
- [ ] Real-time updates (WebSocket/SSE)

### Phase 6: Distributed Execution (v0.7.0)

**Goal**: Task queue integration

**Deliverables**:
- [ ] `CeleryExecutionEngine`
- [ ] `SAQExecutionEngine`
- [ ] `ARQExecutionEngine`
- [ ] Delayed step execution
- [ ] Retry policies
- [ ] Dead letter handling
- [ ] Performance benchmarks

### Phase 7: Production Readiness (v1.0.0)

**Goal**: Stable release

**Deliverables**:
- [ ] Comprehensive documentation (tutorials, API reference, deployment guide)
- [ ] Performance optimization
- [ ] Security audit
- [ ] Multi-tenancy support
- [ ] Metrics/observability hooks
- [ ] Example applications
- [ ] CI/CD for releases

---

## API Reference

### Public API (v1.0.0 target)

```python
# Core
from litestar_workflows import (
    # Protocols
    Step,
    Workflow,
    ExecutionEngine,

    # Types
    StepType,
    StepStatus,
    WorkflowStatus,
    WorkflowContext,
    WorkflowDefinition,
    Edge,

    # Base implementations
    BaseMachineStep,
    BaseHumanStep,

    # Groups
    SequentialGroup,
    ParallelGroup,
    ConditionalGroup,

    # Decorators
    workflow,
    step,
    human_task,

    # Engine
    LocalExecutionEngine,
    WorkflowRegistry,

    # Exceptions
    WorkflowsError,
    WorkflowNotFoundError,
    StepExecutionError,
    InvalidTransitionError,
)

# Database extra
from litestar_workflows.db import (
    WorkflowDefinitionModel,
    WorkflowInstanceModel,
    StepExecutionModel,
    HumanTaskModel,
    WorkflowInstanceRepository,
)

# Web extra
from litestar_workflows.web import (
    WorkflowWebPlugin,
)

# Contrib
from litestar_workflows.contrib.celery import CeleryExecutionEngine
from litestar_workflows.contrib.saq import SAQExecutionEngine
```

---

## Design Decisions

### 1. Protocol-based over ABC-heavy

**Decision**: Use `Protocol` for interfaces, `ABC` sparingly

**Rationale**:
- Structural typing allows duck typing with type checker support
- Users can implement steps without inheriting from base classes
- More Pythonic and flexible

### 2. Async-first

**Decision**: All execution APIs are `async`

**Rationale**:
- Aligns with Litestar's async-first design
- Better performance for I/O-bound workflows
- Human tasks naturally async (waiting for input)
- Easy to wrap sync code with `asyncio.to_thread`

### 3. Context-based state passing

**Decision**: Use `WorkflowContext` dict-like object for state

**Rationale**:
- Flexible schema-less state
- Easy serialization for persistence
- Similar to Prefect/Airflow patterns
- Type safety via typed accessors

### 4. Plugin-based web integration

**Decision**: Separate `[web]` extra with plugin pattern

**Rationale**:
- Core library usable without web dependencies
- Plugin auto-registers routes on user's app
- User controls auth, middleware, path prefix
- Clean separation of concerns

### 5. Repository pattern for persistence

**Decision**: Use repository pattern with protocol

**Rationale**:
- Decouples engine from specific database
- Testable with in-memory implementations
- Aligns with Litestar's SQLAlchemy patterns
- Supports future database backends

### 6. Decorator API as sugar

**Decision**: Support both class-based and decorator-based definition

**Rationale**:
- Class-based for complex workflows
- Decorators for simple/common cases
- Both compile to same `WorkflowDefinition`
- User choice based on preference

---

## References

- [Joeflow Documentation](https://joeflow.readthedocs.io/)
- [Joeflow GitHub](https://github.com/codingjoe/joeflow)
- [Prefect Documentation](https://docs.prefect.io/)
- [Prefect Workflow Design Patterns](https://www.prefect.io/blog/workflow-design-patterns)
- [Airflow Best Practices](https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html)
- [Celery Canvas](https://docs.celeryq.dev/en/stable/userguide/canvas.html)
- [python-statemachine](https://python-statemachine.readthedocs.io/)
- [pytransitions](https://github.com/pytransitions/transitions)
- [Litestar Plugins](https://docs.litestar.dev/latest/usage/plugins/)
- [Litestar SQLAlchemy](https://docs.litestar.dev/latest/usage/databases/sqlalchemy/)

---

*Document Version: 1.3.0*
*Last Updated: 2025-11-26*
*Author: Claude (Architecture Review)*
*Status: Phase 3 complete, all phases merged to main, preparing Pre-Phase 4 stabilization*
